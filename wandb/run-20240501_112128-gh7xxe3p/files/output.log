
Training model:
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DeepfakeDetector                              [320, 1]                  --
├─ResNet: 1-1                                 [320, 1000]               --
│    └─Conv2d: 2-1                            [320, 64, 128, 128]       (9,408)
│    └─BatchNorm2d: 2-2                       [320, 64, 128, 128]       (128)
│    └─ReLU: 2-3                              [320, 64, 128, 128]       --
│    └─MaxPool2d: 2-4                         [320, 64, 64, 64]         --
│    └─Sequential: 2-5                        [320, 64, 64, 64]         --
│    │    └─BasicBlock: 3-1                   [320, 64, 64, 64]         (73,984)
│    │    └─BasicBlock: 3-2                   [320, 64, 64, 64]         (73,984)
│    └─Sequential: 2-6                        [320, 128, 32, 32]        --
│    │    └─BasicBlock: 3-3                   [320, 128, 32, 32]        (230,144)
│    │    └─BasicBlock: 3-4                   [320, 128, 32, 32]        (295,424)
│    └─Sequential: 2-7                        [320, 256, 16, 16]        --
│    │    └─BasicBlock: 3-5                   [320, 256, 16, 16]        (919,040)
│    │    └─BasicBlock: 3-6                   [320, 256, 16, 16]        (1,180,672)
│    └─Sequential: 2-8                        [320, 512, 8, 8]          --
│    │    └─BasicBlock: 3-7                   [320, 512, 8, 8]          (3,673,088)
│    │    └─BasicBlock: 3-8                   [320, 512, 8, 8]          (4,720,640)
│    └─SelectAdaptivePool2d: 2-9              [320, 512]                --
│    │    └─AdaptiveAvgPool2d: 3-9            [320, 512, 1, 1]          --
│    │    └─Flatten: 3-10                     [320, 512]                --
│    └─Linear: 2-10                           [320, 1000]               (513,000)
├─Flatten: 1-2                                [320, 1000]               --
├─Linear: 1-3                                 [320, 1]                  1,001
├─Sigmoid: 1-4                                [320, 1]                  --
===============================================================================================
Total params: 11,690,513
Trainable params: 1,001
Non-trainable params: 11,689,512
Total mult-adds (G): 758.16
===============================================================================================
Input size (MB): 251.66
Forward/backward pass size (MB): 16612.01
Params size (MB): 46.76
Estimated Total Size (MB): 16910.43
===============================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ResNet                                   [32, 1000]                --
├─Conv2d: 1-1                            [32, 64, 128, 128]        (9,408)
├─BatchNorm2d: 1-2                       [32, 64, 128, 128]        (128)
├─ReLU: 1-3                              [32, 64, 128, 128]        --
├─MaxPool2d: 1-4                         [32, 64, 64, 64]          --
├─Sequential: 1-5                        [32, 64, 64, 64]          --
│    └─BasicBlock: 2-1                   [32, 64, 64, 64]          --
│    │    └─Conv2d: 3-1                  [32, 64, 64, 64]          (36,864)
│    │    └─BatchNorm2d: 3-2             [32, 64, 64, 64]          (128)
│    │    └─Identity: 3-3                [32, 64, 64, 64]          --
│    │    └─ReLU: 3-4                    [32, 64, 64, 64]          --
│    │    └─Identity: 3-5                [32, 64, 64, 64]          --
│    │    └─Conv2d: 3-6                  [32, 64, 64, 64]          (36,864)
│    │    └─BatchNorm2d: 3-7             [32, 64, 64, 64]          (128)
│    │    └─ReLU: 3-8                    [32, 64, 64, 64]          --
│    └─BasicBlock: 2-2                   [32, 64, 64, 64]          --
│    │    └─Conv2d: 3-9                  [32, 64, 64, 64]          (36,864)
│    │    └─BatchNorm2d: 3-10            [32, 64, 64, 64]          (128)
│    │    └─Identity: 3-11               [32, 64, 64, 64]          --
│    │    └─ReLU: 3-12                   [32, 64, 64, 64]          --
│    │    └─Identity: 3-13               [32, 64, 64, 64]          --
│    │    └─Conv2d: 3-14                 [32, 64, 64, 64]          (36,864)
│    │    └─BatchNorm2d: 3-15            [32, 64, 64, 64]          (128)
│    │    └─ReLU: 3-16                   [32, 64, 64, 64]          --
├─Sequential: 1-6                        [32, 128, 32, 32]         --
│    └─BasicBlock: 2-3                   [32, 128, 32, 32]         --
│    │    └─Conv2d: 3-17                 [32, 128, 32, 32]         (73,728)
│    │    └─BatchNorm2d: 3-18            [32, 128, 32, 32]         (256)
│    │    └─Identity: 3-19               [32, 128, 32, 32]         --
│    │    └─ReLU: 3-20                   [32, 128, 32, 32]         --
│    │    └─Identity: 3-21               [32, 128, 32, 32]         --
│    │    └─Conv2d: 3-22                 [32, 128, 32, 32]         (147,456)
│    │    └─BatchNorm2d: 3-23            [32, 128, 32, 32]         (256)
│    │    └─Sequential: 3-24             [32, 128, 32, 32]         (8,448)
│    │    └─ReLU: 3-25                   [32, 128, 32, 32]         --
│    └─BasicBlock: 2-4                   [32, 128, 32, 32]         --
│    │    └─Conv2d: 3-26                 [32, 128, 32, 32]         (147,456)
│    │    └─BatchNorm2d: 3-27            [32, 128, 32, 32]         (256)
│    │    └─Identity: 3-28               [32, 128, 32, 32]         --
│    │    └─ReLU: 3-29                   [32, 128, 32, 32]         --
│    │    └─Identity: 3-30               [32, 128, 32, 32]         --
│    │    └─Conv2d: 3-31                 [32, 128, 32, 32]         (147,456)
│    │    └─BatchNorm2d: 3-32            [32, 128, 32, 32]         (256)
│    │    └─ReLU: 3-33                   [32, 128, 32, 32]         --
├─Sequential: 1-7                        [32, 256, 16, 16]         --
│    └─BasicBlock: 2-5                   [32, 256, 16, 16]         --
│    │    └─Conv2d: 3-34                 [32, 256, 16, 16]         (294,912)
│    │    └─BatchNorm2d: 3-35            [32, 256, 16, 16]         (512)
│    │    └─Identity: 3-36               [32, 256, 16, 16]         --
│    │    └─ReLU: 3-37                   [32, 256, 16, 16]         --
│    │    └─Identity: 3-38               [32, 256, 16, 16]         --
│    │    └─Conv2d: 3-39                 [32, 256, 16, 16]         (589,824)
│    │    └─BatchNorm2d: 3-40            [32, 256, 16, 16]         (512)
│    │    └─Sequential: 3-41             [32, 256, 16, 16]         (33,280)
│    │    └─ReLU: 3-42                   [32, 256, 16, 16]         --
│    └─BasicBlock: 2-6                   [32, 256, 16, 16]         --
│    │    └─Conv2d: 3-43                 [32, 256, 16, 16]         (589,824)
│    │    └─BatchNorm2d: 3-44            [32, 256, 16, 16]         (512)
│    │    └─Identity: 3-45               [32, 256, 16, 16]         --
│    │    └─ReLU: 3-46                   [32, 256, 16, 16]         --
│    │    └─Identity: 3-47               [32, 256, 16, 16]         --
│    │    └─Conv2d: 3-48                 [32, 256, 16, 16]         (589,824)
│    │    └─BatchNorm2d: 3-49            [32, 256, 16, 16]         (512)
│    │    └─ReLU: 3-50                   [32, 256, 16, 16]         --
├─Sequential: 1-8                        [32, 512, 8, 8]           --
│    └─BasicBlock: 2-7                   [32, 512, 8, 8]           --
│    │    └─Conv2d: 3-51                 [32, 512, 8, 8]           (1,179,648)
│    │    └─BatchNorm2d: 3-52            [32, 512, 8, 8]           (1,024)
│    │    └─Identity: 3-53               [32, 512, 8, 8]           --
│    │    └─ReLU: 3-54                   [32, 512, 8, 8]           --
│    │    └─Identity: 3-55               [32, 512, 8, 8]           --
│    │    └─Conv2d: 3-56                 [32, 512, 8, 8]           (2,359,296)
│    │    └─BatchNorm2d: 3-57            [32, 512, 8, 8]           (1,024)
│    │    └─Sequential: 3-58             [32, 512, 8, 8]           (132,096)
│    │    └─ReLU: 3-59                   [32, 512, 8, 8]           --
│    └─BasicBlock: 2-8                   [32, 512, 8, 8]           --
│    │    └─Conv2d: 3-60                 [32, 512, 8, 8]           (2,359,296)
│    │    └─BatchNorm2d: 3-61            [32, 512, 8, 8]           (1,024)
│    │    └─Identity: 3-62               [32, 512, 8, 8]           --
│    │    └─ReLU: 3-63                   [32, 512, 8, 8]           --
│    │    └─Identity: 3-64               [32, 512, 8, 8]           --
│    │    └─Conv2d: 3-65                 [32, 512, 8, 8]           (2,359,296)
│    │    └─BatchNorm2d: 3-66            [32, 512, 8, 8]           (1,024)
│    │    └─ReLU: 3-67                   [32, 512, 8, 8]           --
├─SelectAdaptivePool2d: 1-9              [32, 512]                 --
│    └─AdaptiveAvgPool2d: 2-9            [32, 512, 1, 1]           --
│    └─Flatten: 2-10                     [32, 512]                 --
├─Linear: 1-10                           [32, 1000]                (513,000)
==========================================================================================
Total params: 11,689,512
Trainable params: 0
Non-trainable params: 11,689,512
Total mult-adds (G): 75.82
==========================================================================================
Input size (MB): 25.17
Forward/backward pass size (MB): 1661.20
Params size (MB): 46.76
Estimated Total Size (MB): 1733.12
==========================================================================================
Training...
  0%|          | 0/310 [00:00<?, ?it/s]/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([320, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
  0%|          | 0/310 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/raid/home/automathon_2024/account13/anon/automathon-2024/run.py", line 293, in <module>
    loss = loss_fn(label, label_pred)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 3365, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/functional.py", line 76, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
RuntimeError: The size of tensor a (32) must match the size of tensor b (320) at non-singleton dimension 0