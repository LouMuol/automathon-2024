Using cuda
Training model:
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DeepfakeDetector                         [32, 1]                   --
├─Conv3d: 1-1                            [32, 16, 8, 254, 254]     1,312
├─LeakyReLU: 1-2                         [32, 16, 8, 254, 254]     --
├─MaxPool3d: 1-3                         [32, 16, 4, 127, 127]     --
├─Conv3d: 1-4                            [32, 32, 2, 125, 125]     13,856
├─LeakyReLU: 1-5                         [32, 32, 2, 125, 125]     --
├─MaxPool3d: 1-6                         [32, 32, 1, 62, 62]       --
├─Flatten: 1-7                           [32, 123008]              --
├─Linear: 1-8                            [32, 1]                   123,009
├─Sigmoid: 1-9                           [32, 1]                   --
==========================================================================================
Total params: 138,177
Trainable params: 138,177
Non-trainable params: 0
Total mult-adds (G): 35.53
==========================================================================================
Input size (MB): 251.66
Forward/backward pass size (MB): 2370.06
Params size (MB): 0.55
Estimated Total Size (MB): 2622.27
==========================================================================================
Training...
Epoch 0
/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv3d(













































































 99%|█████████▊| 306/310 [02:35<00:02,  1.99it/s]
100%|██████████| 310/310 [02:37<00:00,  1.97it/s]









































































 99%|█████████▉| 308/310 [02:26<00:00,  2.08it/s]
100%|██████████| 310/310 [02:27<00:00,  2.11it/s]







































































 99%|█████████▉| 307/310 [02:23<00:01,  2.16it/s]
100%|██████████| 310/310 [02:25<00:00,  2.14it/s]








































































 99%|█████████▉| 307/310 [02:24<00:01,  2.19it/s]
100%|██████████| 310/310 [02:26<00:00,  2.12it/s]









































































 99%|█████████▉| 307/310 [02:26<00:01,  2.14it/s]
100%|██████████| 310/310 [02:28<00:00,  2.09it/s]

















100%|██████████| 94/94 [00:34<00:00,  2.72it/s]
Saving...