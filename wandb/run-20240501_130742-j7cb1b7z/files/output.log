
Using cuda
Training model:
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DeepfakeDetector                              [32, 1]                   --
├─Flatten: 1-1                                [320, 3, 256, 256]        --
├─ResNet: 1-2                                 [320, 1000]               --
│    └─Conv2d: 2-1                            [320, 64, 128, 128]       (9,408)
│    └─BatchNorm2d: 2-2                       [320, 64, 128, 128]       (128)
│    └─ReLU: 2-3                              [320, 64, 128, 128]       --
│    └─MaxPool2d: 2-4                         [320, 64, 64, 64]         --
│    └─Sequential: 2-5                        [320, 64, 64, 64]         --
│    │    └─BasicBlock: 3-1                   [320, 64, 64, 64]         (73,984)
│    │    └─BasicBlock: 3-2                   [320, 64, 64, 64]         (73,984)
│    └─Sequential: 2-6                        [320, 128, 32, 32]        --
│    │    └─BasicBlock: 3-3                   [320, 128, 32, 32]        (230,144)
│    │    └─BasicBlock: 3-4                   [320, 128, 32, 32]        (295,424)
│    └─Sequential: 2-7                        [320, 256, 16, 16]        --
│    │    └─BasicBlock: 3-5                   [320, 256, 16, 16]        (919,040)
│    │    └─BasicBlock: 3-6                   [320, 256, 16, 16]        (1,180,672)
│    └─Sequential: 2-8                        [320, 512, 8, 8]          --
│    │    └─BasicBlock: 3-7                   [320, 512, 8, 8]          (3,673,088)
│    │    └─BasicBlock: 3-8                   [320, 512, 8, 8]          (4,720,640)
│    └─SelectAdaptivePool2d: 2-9              [320, 512]                --
│    │    └─AdaptiveAvgPool2d: 3-9            [320, 512, 1, 1]          --
│    │    └─Flatten: 3-10                     [320, 512]                --
│    └─Linear: 2-10                           [320, 1000]               (513,000)
├─Unflatten: 1-3                              [32, 10, 1000]            --
├─Flatten: 1-4                                [32, 10000]               --
├─Linear: 1-5                                 [32, 1]                   10,001
├─Sigmoid: 1-6                                [32, 1]                   --
===============================================================================================
Total params: 11,699,513
Trainable params: 10,001
Non-trainable params: 11,689,512
Total mult-adds (G): 758.16
===============================================================================================
Input size (MB): 251.66
Forward/backward pass size (MB): 16612.00
Params size (MB): 46.80
Estimated Total Size (MB): 16910.46
===============================================================================================
Training...

















































































 99%|█████████▉| 307/310 [02:43<00:01,  1.94it/s]
100%|█████████▉| 309/310 [02:44<00:00,  1.88it/s]
Traceback (most recent call last):
  File "/raid/home/automathon_2024/account13/anon/automathon-2024/run.py", line 298, in <module>
    label_pred = model(X)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/automathon_2024/account13/anon/automathon-2024/run.py", line 262, in forward
    y = self.unflatten(y)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/flatten.py", line 141, in forward
    return input.unflatten(self.dim, self.unflattened_size)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/_tensor.py", line 1307, in unflatten
    return super().unflatten(dim, sizes)
RuntimeError: unflatten: Provided sizes [32, 10] don't multiply up to the size of dim 0 (260) in the input tensor