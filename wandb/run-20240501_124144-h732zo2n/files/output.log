
Using cuda
Training model:
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DeepfakeDetector                              [32, 10, 3, 256, 256]     --
├─Flatten: 1-1                                [320, 3, 256, 256]        --
├─ResNet: 1-2                                 [320, 1000]               --
│    └─Conv2d: 2-1                            [320, 64, 128, 128]       (9,408)
│    └─BatchNorm2d: 2-2                       [320, 64, 128, 128]       (128)
│    └─ReLU: 2-3                              [320, 64, 128, 128]       --
│    └─MaxPool2d: 2-4                         [320, 64, 64, 64]         --
│    └─Sequential: 2-5                        [320, 64, 64, 64]         --
│    │    └─BasicBlock: 3-1                   [320, 64, 64, 64]         (73,984)
│    │    └─BasicBlock: 3-2                   [320, 64, 64, 64]         (73,984)
│    └─Sequential: 2-6                        [320, 128, 32, 32]        --
│    │    └─BasicBlock: 3-3                   [320, 128, 32, 32]        (230,144)
│    │    └─BasicBlock: 3-4                   [320, 128, 32, 32]        (295,424)
│    └─Sequential: 2-7                        [320, 256, 16, 16]        --
│    │    └─BasicBlock: 3-5                   [320, 256, 16, 16]        (919,040)
│    │    └─BasicBlock: 3-6                   [320, 256, 16, 16]        (1,180,672)
│    └─Sequential: 2-8                        [320, 512, 8, 8]          --
│    │    └─BasicBlock: 3-7                   [320, 512, 8, 8]          (3,673,088)
│    │    └─BasicBlock: 3-8                   [320, 512, 8, 8]          (4,720,640)
│    └─SelectAdaptivePool2d: 2-9              [320, 512]                --
│    │    └─AdaptiveAvgPool2d: 3-9            [320, 512, 1, 1]          --
│    │    └─Flatten: 3-10                     [320, 512]                --
│    └─Linear: 2-10                           [320, 1000]               (513,000)
├─Unflatten: 1-3                              [32, 10, 1000]            --
├─Flatten: 1-4                                [32, 10000]               --
├─Linear: 1-5                                 [32, 1]                   10,001
├─Sigmoid: 1-6                                [32, 1]                   --
===============================================================================================
Total params: 11,699,513
Trainable params: 10,001
Non-trainable params: 11,689,512
Total mult-adds (G): 758.16
===============================================================================================
Input size (MB): 251.66
Forward/backward pass size (MB): 16612.00
Params size (MB): 46.80
Estimated Total Size (MB): 16910.46
===============================================================================================
Training...
  0%|          | 0/310 [00:00<?, ?it/s]/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 10, 3, 256, 256])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
  0%|          | 0/310 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/raid/home/automathon_2024/account13/anon/automathon-2024/run.py", line 300, in <module>
    loss = loss_fn(label, label_pred)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 3365, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  File "/raid/home/automathon_2024/account13/.local/lib/python3.10/site-packages/torch/functional.py", line 76, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
RuntimeError: The size of tensor a (32) must match the size of tensor b (256) at non-singleton dimension 3